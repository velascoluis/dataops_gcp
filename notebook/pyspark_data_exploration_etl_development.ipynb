{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c53c6e9-6100-4b45-837c-fcd64d521814",
   "metadata": {},
   "source": [
    "# Data exploration and ETL development using `pySpark`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40371314-ef84-410e-bc05-6e79ae8b569f",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684868d4-ff81-448b-a237-cd552bfc3d65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://gdpic-srvls-session-b7e598f5-1948-4628-981d-261519df0647-m.us-central1-c.c.velascoluis-dev-sandbox.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://gdpic-srvls-session-b7e598f5-1948-4628-981d-261519df0647-m:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa9808a1b50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae375f5-c62b-4762-a344-2daffd7b22c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2860145-6dda-4a9f-8719-fdc87375faf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+\n",
      "|        airport_name|average_departure_delay|\n",
      "+--------------------+-----------------------+\n",
      "|Los Angeles Inter...|                   30.0|\n",
      "|    Heathrow Airport|                   15.0|\n",
      "|John F. Kennedy I...|                    0.0|\n",
      "+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "fact_flight = spark.read.format('bigquery').option('table','airline.fact_flight').load()\n",
    "dim_flight = spark.read.format('bigquery').option('table','airline.dim_flight').load()\n",
    "dim_airport = spark.read.format('bigquery').option('table','airline.dim_airport').load()\n",
    "\n",
    "# Perform the joins and aggregation\n",
    "result = (fact_flight.alias(\"f\")\n",
    "          .join(dim_flight.alias(\"df\"), col(\"f.flight_key\") == col(\"df.flight_key\"), \"inner\")\n",
    "          .join(dim_airport.alias(\"a\"), col(\"df.departure_airport_key\") == col(\"a.airport_key\"), \"inner\")\n",
    "          .groupBy(\"a.airport_name\")\n",
    "          .agg(avg(\"f.departure_delay\").alias(\"average_departure_delay\"))\n",
    "          .orderBy(desc(\"average_departure_delay\")))\n",
    "\n",
    "\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23399e52-aead-44df-a131-2a4a6eb0d015",
   "metadata": {},
   "source": [
    "### sparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bf35a0f-640b-4cc7-96a8-5755ace02858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fact_flight.createOrReplaceTempView(\"fact_flight\")\n",
    "dim_flight.createOrReplaceTempView(\"dim_flight\")\n",
    "dim_airport.createOrReplaceTempView(\"dim_airport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68100a6d-4415-4510-920d-e15fee54757a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">airport_name</td><td style=\"font-weight: bold\">average_departure_delay</td></tr><tr><td>Los Angeles International Airport</td><td>30.0</td></tr><tr><td>Heathrow Airport</td><td>15.0</td></tr><tr><td>John F. Kennedy International Airport</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT\n",
    "    a.airport_name,\n",
    "    AVG(f.departure_delay) AS average_departure_delay\n",
    "FROM\n",
    "    fact_flight AS f\n",
    "JOIN\n",
    "    dim_flight AS df ON f.flight_key = df.flight_key\n",
    "JOIN\n",
    "    dim_airport AS a ON df.departure_airport_key = a.airport_key\n",
    "GROUP BY\n",
    "    a.airport_name\n",
    "ORDER BY\n",
    "    average_departure_delay DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a82b9-03eb-4735-9980-e59f67e733a4",
   "metadata": {},
   "source": [
    "## ETL Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b90c0-caf2-4872-8c57-e19dc7433a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce, col, when, avg, lit\n",
    "\n",
    "\n",
    "fact_flight = spark.read.format('bigquery').option('table','airline.fact_flight').load()\n",
    "\n",
    "\n",
    "etl_step_1_delays = (fact_flight\n",
    "                     .select(\"flight_key\",\n",
    "                             (coalesce(\"departure_delay\", lit(0)) + coalesce(\"arrival_delay\", lit(0))).alias(\"total_delay\"),  \n",
    "                             when((coalesce(\"departure_delay\", lit(0)) + coalesce(\"arrival_delay\", lit(0))) <= 0, 1).otherwise(0).alias(\"on_time_performance\"))) \n",
    "\n",
    "etl_step_1_delays.write.mode('overwrite').format('bigquery').option(\"writeMethod\", \"direct\").option('table', 'airline.etl_step_1_delays_spark').save()\n",
    "\n",
    "\n",
    "# --- Step 2: Join with dim_flight and dim_airport ---\n",
    "dim_flight = spark.read.format('bigquery').option('table','airline.dim_flight').load()\n",
    "dim_airport = spark.read.format('bigquery').option('table','airline.dim_airport').load()\n",
    "\n",
    "\n",
    "etl_step_2_flight_delays_with_airports = (etl_step_1_delays.alias(\"d\")\n",
    "                                         .join(dim_flight.alias(\"df\"), col(\"d.flight_key\") == col(\"df.flight_key\"), \"inner\")\n",
    "                                         .join(dim_airport.alias(\"a\"), col(\"df.departure_airport_key\") == col(\"a.airport_key\"), \"inner\")\n",
    "                                         .select(\"d.total_delay\", \"d.on_time_performance\", \"a.airport_name\"))\n",
    "\n",
    "etl_step_2_flight_delays_with_airports.write.mode('overwrite').format('bigquery').option(\"writeMethod\", \"direct\").option('table', 'airline.etl_step_2_flight_delays_with_airports_spark').save()\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 3: Aggregate by airport ---\n",
    "etl_step_3_airport_performance = (etl_step_2_flight_delays_with_airports.alias(\"a\")\n",
    "                                  .groupBy(\"a.airport_name\")\n",
    "                                  .agg(avg(\"a.total_delay\").alias(\"average_total_delay\"),\n",
    "                                       avg(\"a.on_time_performance\").alias(\"on_time_percentage\")))\n",
    "\n",
    "\n",
    "etl_step_3_airport_performance.write.mode('overwrite').format('bigquery').option(\"writeMethod\", \"direct\").option('table', 'airline.etl_step_3_airport_performance_spark').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a77e4a-0548-4a46-a4e3-ccfd109e9e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "etl_step_3_airport_performance.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2cec5-d391-4e35-bbc5-d6d647767c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "9c39b79e5d2e7072beb4bd59-runtime-00003ea3799b",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "spark-runtime-next on Serverless Spark (Remote)",
   "language": "python",
   "name": "9c39b79e5d2e7072beb4bd59-runtime-00003ea3799b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
